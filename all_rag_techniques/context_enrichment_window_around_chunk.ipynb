{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/context_enrichment_window_around_chunk.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用于文档检索的上下文丰富窗口\n",
    "\n",
    "## 概述\n",
    "\n",
    "此代码实现了一种用于在向量数据库中进行文档检索的上下文丰富窗口技术。它通过为每个检索到的块添加周围的上下文来增强标准检索过程，从而提高返回信息的连贯性和完整性。\n",
    "\n",
    "## 动机\n",
    "\n",
    "传统的向量搜索通常返回孤立的文本块，这可能缺乏充分理解所需的必要上下文。这种方法旨在通过包含相邻的文本块来提供对检索信息的更全面的视图。\n",
    "\n",
    "## 关键组件\n",
    "\n",
    "1. PDF 处理和文本分块\n",
    "2. 使用 FAISS 和 OpenAI 嵌入创建向量存储\n",
    "3. 带有上下文窗口的自定义检索功能\n",
    "4. 标准检索与上下文丰富检索的比较\n",
    "\n",
    "## 方法详情\n",
    "\n",
    "### 文档预处理\n",
    "\n",
    "1. 读取 PDF 并将其转换为字符串。\n",
    "2. 将文本分割成带有重叠的块，每个块都用其索引进行标记。\n",
    "\n",
    "### 向量存储创建\n",
    "\n",
    "1. 使用 OpenAI 嵌入来创建块的向量表示。\n",
    "2. 从这些嵌入中创建一个 FAISS 向量存储。\n",
    "\n",
    "### 上下文丰富的检索\n",
    "\n",
    "1. `retrieve_with_context_overlap` 函数执行以下步骤：\n",
    "   - 根据查询检索相关块\n",
    "   - 对于每个相关块，获取相邻的块\n",
    "   - 连接这些块，并考虑重叠部分\n",
    "   - 返回每个相关块的扩展上下文\n",
    "\n",
    "### 检索比较\n",
    "\n",
    "笔记本中包含一个部分，用于比较标准检索与上下文丰富的方法。\n",
    "\n",
    "## 此方法的优点\n",
    "\n",
    "1. 提供更连贯、上下文更丰富的结果\n",
    "2. 在保持向量搜索优势的同时，减轻其返回孤立文本片段的倾向\n",
    "3. 允许灵活调整上下文窗口的大小\n",
    "\n",
    "## 结论\n",
    "\n",
    "这种上下文丰富窗口技术为提高基于向量的文档搜索系统中检索信息的质量提供了一种有前途的方法。通过提供周围的上下文，它有助于保持检索信息的连贯性和完整性，从而可能在问答等下游任务中带来更好的理解和更准确的响应。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "\n",
    "<img src=\"../images/vector-search-comparison_context_enrichment.svg\" alt=\"context enrichment window\" style=\"width:70%; height:auto;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "\n",
    "<img src=\"../images/context_enrichment_window.svg\" alt=\"context enrichment window\" style=\"width:70%; height:auto;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 包安装和导入\n",
    "\n",
    "下面的单元格安装了运行此笔记本所需的所有必要软件包。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 安装所需的包\n",
    "!pip install langchain python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 克隆存储库以访问辅助函数和评估模块\n",
    "!git clone https://github.com/NirDiamant/RAG_TECHNIQUES.git\n",
    "import sys\n",
    "sys.path.append('RAG_TECHNIQUES')\n",
    "# 如果您需要使用最新数据运行\n",
    "# !cp -r RAG_TECHNIQUES/data ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\N7\\PycharmProjects\\llm_tasks\\RAG_TECHNIQUES\\.venv\\Lib\\site-packages\\deepeval\\__init__.py:45: UserWarning: You are using deepeval version 0.21.73, however version 0.21.78 is available. You should consider upgrading via the \"pip install --upgrade deepeval\" command.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "\n",
    "# 为 Colab 兼容性替换了原始路径附加\n",
    "from helper_functions import *\n",
    "from evaluation.evalute_rag import *\n",
    "\n",
    "# 从 .env 文件加载环境变量\n",
    "load_dotenv()\n",
    "\n",
    "# 设置 OpenAI API 密钥环境变量\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义 PDF 路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下载所需的数据文件\n",
    "import os\n",
    "os.makedirs('data', exist_ok=True)\n",
    "\n",
    "# 下载本笔记本中使用的 PDF 文档\n",
    "!wget -O data/Understanding_Climate_Change.pdf https://raw.githubusercontent.com/NirDiamant/RAG_TECHNIQUES/main/data/Understanding_Climate_Change.pdf\n",
    "!wget -O data/Understanding_Climate_Change.pdf https://raw.githubusercontent.com/NirDiamant/RAG_TECHNIQUES/main/data/Understanding_Climate_Change.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/Understanding_Climate_Change.pdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将 PDF 读取为字符串"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = read_pdf_to_string(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将文本拆分为块并附带块按时间顺序索引的元数据的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text_to_chunks_with_indices(text: str, chunk_size: int, chunk_overlap: int) -> List[Document]:\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(text):\n",
    "        end = start + chunk_size\n",
    "        chunk = text[start:end]\n",
    "        chunks.append(Document(page_content=chunk, metadata={\"index\": len(chunks), \"text\": text}))\n",
    "        start += chunk_size - chunk_overlap\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 相应地拆分我们的文档"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_size = 400\n",
    "chunk_overlap = 200\n",
    "docs = split_text_to_chunks_with_indices(content, chunks_size, chunk_overlap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建向量存储和检索器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = FAISS.from_documents(docs, embeddings)\n",
    "chunks_query_retriever = vectorstore.as_retriever(search_kwargs={\"k\": 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 从向量存储中提取第 k<sup>th</sup> 个块（按原始顺序）的函数 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chunk_by_index(vectorstore, target_index: int) -> Document:\n",
    "    \"\"\"\n",
    "    根据元数据中的索引从向量存储中检索块。\n",
    "    \n",
    "    参数：\n",
    "    vectorstore (VectorStore): 包含块的向量存储。\n",
    "    target_index (int): 要检索的块的索引。\n",
    "    \n",
    "    返回：\n",
    "    Optional[Document]: 作为 Document 对象检索到的块，如果未找到则为 None。\n",
    "    \"\"\"\n",
    "    # 这是一个简化版本。在实践中，您可能需要一种更有效的方法\n",
    "    # 来根据索引检索块，具体取决于您的向量存储实现。\n",
    "    all_docs = vectorstore.similarity_search(\"\", k=vectorstore.index.ntotal)\n",
    "    for doc in all_docs:\n",
    "        if doc.metadata.get('index') == target_index:\n",
    "            return doc\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 检查功能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Understanding Climate Change \n",
      "Chapter 1: Introduction to Climate Change \n",
      "Climate change refers to significant, long-term changes in the global climate. The term \n",
      "\"global climate\" encompasses the planet's overall weather patterns, including temperature, \n",
      "precipitation, and wind patterns, over an extended period. Over the past century, human \n",
      "activities, particularly the burning of fossil fuels and \n"
     ]
    }
   ],
   "source": [
    "chunk = get_chunk_by_index(vectorstore, 0)\n",
    "print(chunk.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基于语义相似性从向量存储中检索，然后用其前后的 num_neighbors 填充每个检索到的块，同时考虑块重叠以在其周围构建一个有意义的宽窗口的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_with_context_overlap(vectorstore, retriever, query: str, num_neighbors: int = 1, chunk_size: int = 200, chunk_overlap: int = 20) -> List[str]:\n",
    "    \"\"\"\n",
    "    根据查询检索块，然后获取相邻块并将其连接起来，\n",
    "    同时考虑重叠和正确的索引。\n",
    "\n",
    "    参数：\n",
    "    vectorstore (VectorStore): 包含块的向量存储。\n",
    "    retriever: 用于获取相关文档的检索器对象。\n",
    "    query (str): 用于搜索相关块的查询。\n",
    "    num_neighbors (int): 在每个相关块之前和之后要检索的块数。\n",
    "    chunk_size (int): 最初拆分时每个块的大小。\n",
    "    chunk_overlap (int): 最初拆分时块之间的重叠。\n",
    "\n",
    "    返回：\n",
    "    List[str]: 连接的块序列列表，每个序列都以一个相关块为中心。\n",
    "    \"\"\"\n",
    "    relevant_chunks = retriever.get_relevant_documents(query)\n",
    "    result_sequences = []\n",
    "\n",
    "    for chunk in relevant_chunks:\n",
    "        current_index = chunk.metadata.get('index')\n",
    "        if current_index is None:\n",
    "            continue\n",
    "\n",
    "        # 确定要检索的块的范围\n",
    "        start_index = max(0, current_index - num_neighbors)\n",
    "        end_index = current_index + num_neighbors + 1  # +1 因为范围在末尾是排他的\n",
    "\n",
    "        # 检索范围内的所有块\n",
    "        neighbor_chunks = []\n",
    "        for i in range(start_index, end_index):\n",
    "            neighbor_chunk = get_chunk_by_index(vectorstore, i)\n",
    "            if neighbor_chunk:\n",
    "                neighbor_chunks.append(neighbor_chunk)\n",
    "\n",
    "        # 按索引对块进行排序以确保正确的顺序\n",
    "        neighbor_chunks.sort(key=lambda x: x.metadata.get('index', 0))\n",
    "\n",
    "        # 连接块，考虑重叠\n",
    "        concatenated_text = neighbor_chunks[0].page_content\n",
    "        for i in range(1, len(neighbor_chunks)):\n",
    "            current_chunk = neighbor_chunks[i].page_content\n",
    "            overlap_start = max(0, len(concatenated_text) - chunk_overlap)\n",
    "            concatenated_text = concatenated_text[:overlap_start] + current_chunk\n",
    "\n",
    "        result_sequences.append(concatenated_text)\n",
    "\n",
    "    return result_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 比较常规检索和带上下文窗口的检索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基线方法\n",
    "query = \"Explain the role of deforestation and fossil fuels in climate change.\"\n",
    "baseline_chunk = chunks_query_retriever.get_relevant_documents(query\n",
    "    ,\n",
    "    k=1\n",
    ")\n",
    "# 聚焦上下文丰富方法\n",
    "enriched_chunks = retrieve_with_context_overlap(\n",
    "    vectorstore,\n",
    "    chunks_query_retriever,\n",
    "    query,\n",
    "    num_neighbors=1,\n",
    "    chunk_size=400,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "\n",
    "print(\"Baseline Chunk:\")\n",
    "print(baseline_chunk[0].page_content)\n",
    "print(\"\\nEnriched Chunks:\")\n",
    "print(enriched_chunks[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一个展示附加上下文窗口优越性的示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regular retrieval:\n",
      "\n",
      "Context 1:\n",
      "\n",
      "Deep Learning, a subset of machine learning using neural networks with many layers, began to show promising results in the early 2010s. The breakthrough came in 2012 when a deep neural network significantly outperformed other machine learning method\n",
      "\n",
      "\n",
      "\n",
      "Retrieval with context overlap:\n",
      "\n",
      "Context 1:\n",
      "ng multi-layer networks during this time.\n",
      "\n",
      "The late 1990s and 2000s marked the rise of machine learning approaches. Support Vector Machines (SVMs) and Random Forests became popular for various classification and regression tasks.\n",
      "\n",
      "Deep Learning, a subset of machine learning using neural networks with many layers, began to show promising results in the early 2010s. The breakthrough came in 2012 when a deep neural network significantly outperformed other machine learning methods in the ImageNet competition.\n",
      "\n",
      "Since then, deep learning has revolutionized many AI applications, including image and speech recognition, natural language processing, and game playing. In 2016, Google's AlphaGo defeated a world c\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "document_content = \"\"\"\n",
    "Artificial Intelligence (AI) has a rich history dating back to the mid-20th century. The term \"Artificial Intelligence\" was coined in 1956 at the Dartmouth Conference, marking the field's official beginning.\n",
    "\n",
    "In the 1950s and 1960s, AI research focused on symbolic methods and problem-solving. The Logic Theorist, created in 1955 by Allen Newell and Herbert A. Simon, is often considered the first AI program.\n",
    "\n",
    "The 1960s saw the development of expert systems, which used predefined rules to solve complex problems. DENDRAL, created in 1965, was one of the first expert systems, designed to analyze chemical compounds.\n",
    "\n",
    "However, the 1970s brought the first \"AI Winter,\" a period of reduced funding and interest in AI research, largely due to overpromised capabilities and underdelivered results.\n",
    "\n",
    "The 1980s saw a resurgence with the popularization of expert systems in corporations. The Japanese government's Fifth Generation Computer Project also spurred increased investment in AI research globally.\n",
    "\n",
    "Neural networks gained prominence in the 1980s and 1990s. The backpropagation algorithm, although discovered earlier, became widely used for training multi-layer networks during this time.\n",
    "\n",
    "The late 1990s and 2000s marked the rise of machine learning approaches. Support Vector Machines (SVMs) and Random Forests became popular for various classification and regression tasks.\n",
    "\n",
    "Deep Learning, a subset of machine learning using neural networks with many layers, began to show promising results in the early 2010s. The breakthrough came in 2012 when a deep neural network significantly outperformed other machine learning methods in the ImageNet competition.\n",
    "\n",
    "Since then, deep learning has revolutionized many AI applications, including image and speech recognition, natural language processing, and game playing. In 2016, Google's AlphaGo defeated a world champion Go player, a landmark achievement in AI.\n",
    "\n",
    "The current era of AI is characterized by the integration of deep learning with other AI techniques, the development of more efficient and powerful hardware, and the ethical considerations surrounding AI deployment.\n",
    "\n",
    "Transformers, introduced in 2017, have become a dominant architecture in natural language processing, enabling models like GPT (Generative Pre-trained Transformer) to generate human-like text.\n",
    "\n",
    "As AI continues to evolve, new challenges and opportunities arise. Explainable AI, robust and fair machine learning, and artificial general intelligence (AGI) are among the key areas of current and future research in the field.\n",
    "\"\"\"\n",
    "\n",
    "chunks_size = 250\n",
    "chunk_overlap = 20\n",
    "document_chunks = split_text_to_chunks_with_indices(document_content, chunks_size, chunk_overlap)\n",
    "document_vectorstore = FAISS.from_documents(document_chunks, embeddings)\n",
    "document_retriever = document_vectorstore.as_retriever(search_kwargs={\"k\": 1})\n",
    "\n",
    "query = \"When did deep learning become prominent in AI?\"\n",
    "context = document_retriever.get_relevant_documents(query)\n",
    "context_pages_content = [doc.page_content for doc in context]\n",
    "\n",
    "print(\"Regular retrieval:\\n\")\n",
    "show_context(context_pages_content)\n",
    "\n",
    "sequences = retrieve_with_context_overlap(document_vectorstore, document_retriever, query, num_neighbors=1)\n",
    "print(\"\\nRetrieval with context enrichment:\\n\")\n",
    "show_context(sequences)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
