{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/crag.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 纠正性 RAG 流程：具有动态纠正功能的检索增强生成\n",
    "\n",
    "## 概述\n",
    "\n",
    "纠正性 RAG（检索增强生成）流程是一种先进的信息检索和响应生成系统。它通过动态评估和纠正检索过程来扩展标准 RAG 方法，结合了向量数据库、网络搜索和语言模型的强大功能，为用户查询提供准确且具有上下文感知能力的响应。\n",
    "\n",
    "## 动机\n",
    "\n",
    "虽然传统的 RAG 系统改进了信息检索和响应生成，但当检索到的信息不相关或过时时，它们仍然可能存在不足。纠正性 RAG 流程通过以下方式解决了这些限制：\n",
    "\n",
    "1. 利用预先存在的知识库\n",
    "2. 评估检索信息的相关性\n",
    "3. 必要时动态搜索网络\n",
    "4. 提炼和组合来自多个来源的知识\n",
    "5. 基于最合适的知识生成类似人类的响应\n",
    "\n",
    "## 关键组件\n",
    "\n",
    "1. **FAISS 索引**：用于对预先存在的知识进行高效相似性搜索的向量数据库。\n",
    "2. **检索评估器**：评估检索到的文档与查询的相关性。\n",
    "3. **知识提炼**：必要时从文档中提取关键信息。\n",
    "4. **网络搜索查询重写器**：当本地知识不足时，优化网络搜索的查询。\n",
    "5. **响应生成器**：基于累积的知识创建类似人类的响应。\n",
    "\n",
    "## 方法详情\n",
    "\n",
    "1. **文档检索**：\n",
    "   - 在 FAISS 索引中执行相似性搜索以查找相关文档。\n",
    "   - 检索前 k 个文档（默认为 k=3）。\n",
    "\n",
    "2. **文档评估**：\n",
    "   - 计算每个检索到的文档的相关性得分。\n",
    "   - 根据最高相关性得分确定最佳行动方案。\n",
    "\n",
    "3. **纠正性知识获取**：\n",
    "   - 如果相关性高（得分 > 0.7）：按原样使用最相关的文档。\n",
    "   - 如果相关性低（得分 < 0.3）：通过使用重写的查询执行网络搜索进行纠正。\n",
    "   - 如果模棱两可（0.3 ≤ 得分 ≤ 0.7）：通过将最相关的文档与网络搜索结果相结合进行纠正。\n",
    "\n",
    "4. **自适应知识处理**：\n",
    "   - 对于网络搜索结果：提炼知识以提取要点。\n",
    "   - 对于模棱两可的情况：将原始文档内容与提炼后的网络搜索结果相结合。\n",
    "\n",
    "5. **响应生成**：\n",
    "   - 使用语言模型根据查询和获取的知识生成类似人类的响应。\n",
    "   - 在响应中包含源信息以实现透明度。\n",
    "\n",
    "## 纠正性 RAG 方法的优点\n",
    "\n",
    "1. **动态纠正**：适应检索信息的质量，确保相关性和准确性。\n",
    "2. **灵活性**：根据需要利用预先存在的知识和网络搜索。\n",
    "3. **准确性**：在使用信息之前评估其相关性，确保高质量的响应。\n",
    "4. **透明度**：提供源信息，允许用户验证信息的来源。\n",
    "5. **效率**：使用向量搜索从大型知识库中快速检索。\n",
    "6. **上下文理解**：必要时组合多个信息源以提供全面的响应。\n",
    "7. **最新信息**：可以用当前的网络信息补充或替换过时的本地知识。\n",
    "\n",
    "## 结论\n",
    "\n",
    "纠正性 RAG 流程代表了标准 RAG 方法的复杂演变。通过智能地评估和纠正检索过程，它克服了传统 RAG 系统的常见限制。这种动态方法确保响应基于最相关和最新的可用信息，无论是来自本地知识库还是网络。该系统能够根据相关性得分调整其信息来源策略，使其特别适用于需要高精度和当前信息的应用，例如研究辅助、动态知识库和高级问答系统。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "\n",
    "<img src=\"../images/crag.svg\" alt=\"Corrective RAG\" style=\"width:80%; height:auto;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 包安装和导入\n",
    "\n",
    "下面的单元格安装了运行此笔记本所需的所有必要软件包。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 安装所需的包\n",
    "!pip install langchain langchain-openai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 克隆存储库以访问辅助函数和评估模块\n",
    "!git clone https://github.com/NirDiamant/RAG_TECHNIQUES.git\n",
    "import sys\n",
    "sys.path.append('RAG_TECHNIQUES')\n",
    "# 如果您需要使用最新数据运行\n",
    "# !cp -r RAG_TECHNIQUES/data ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "\n",
    "# 为 Colab 兼容性替换了原始路径附加\n",
    "from helper_functions import *\n",
    "from evaluation.evalute_rag import *\n",
    "\n",
    "# 从 .env 文件加载环境变量\n",
    "load_dotenv()\n",
    "\n",
    "# 设置 OpenAI API 密钥环境变量\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')\n",
    "from langchain.tools import DuckDuckGoSearchResults\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义文件路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下载所需的数据文件\n",
    "import os\n",
    "os.makedirs('data', exist_ok=True)\n",
    "\n",
    "# 下载本笔记本中使用的 PDF 文档\n",
    "!wget -O data/Understanding_Climate_Change.pdf https://raw.githubusercontent.com/NirDiamant/RAG_TECHNIQUES/main/data/Understanding_Climate_Change.pdf\n",
    "!wget -O data/Understanding_Climate_Change.pdf https://raw.githubusercontent.com/NirDiamant/RAG_TECHNIQUES/main/data/Understanding_Climate_Change.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/Understanding_Climate_Change.pdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建向量存储"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = encode_pdf(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 初始化 OpenAI 语言模型\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", max_tokens=1000, temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 初始化搜索工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = DuckDuckGoSearchResults()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义检索评估器、知识提炼和查询重写器的 LLM 链"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检索评估器\n",
    "class RetrievalEvaluatorInput(BaseModel):\n",
    "    relevance_score: float = Field(..., description=\"文档与查询的相关性得分。得分应该在 0 和 1 之间。\")\n",
    "def retrieval_evaluator(query: str, document: str) -> float:\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"query\", \"document\"],\n",
    "        template=\"On a scale from 0 to 1, how relevant is the following document to the query? Query: {query}\\nDocument: {document}\\nRelevance score:\"\n",
    "    )\n",
    "    chain = prompt | llm.with_structured_output(RetrievalEvaluatorInput)\n",
    "    input_variables = {\"query\": query, \"document\": document}\n",
    "    result = chain.invoke(input_variables).relevance_score\n",
    "    return result\n",
    "\n",
    "# 知识提炼\n",
    "class KnowledgeRefinementInput(BaseModel):\n",
    "    key_points: str = Field(..., description=\"要从中提取关键信息的文档。\")\n",
    "def knowledge_refinement(document: str) -> List[str]:\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"document\"],\n",
    "        template=\"Extract the key information from the following document in bullet points:\\n{document}\\nKey points:\"\n",
    "    )\n",
    "    chain = prompt | llm.with_structured_output(KnowledgeRefinementInput)\n",
    "    input_variables = {\"document\": document}\n",
    "    result = chain.invoke(input_variables).key_points\n",
    "    return [point.strip() for point in result.split('\\n') if point.strip()]\n",
    "\n",
    "# 网络搜索查询重写器\n",
    "class QueryRewriterInput(BaseModel):\n",
    "    query: str = Field(..., description=\"要重写的查询。\")\n",
    "def rewrite_query(query: str) -> str:\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"query\"],\n",
    "        template=\"Rewrite the following query to make it more suitable for a web search:\\n{query}\\nRewritten query:\"\n",
    "    )\n",
    "    chain = prompt | llm.with_structured_output(QueryRewriterInput)\n",
    "    input_variables = {\"query\": query}\n",
    "    return chain.invoke(input_variables).query.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 解析搜索结果的辅助函数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_search_results(results_string: str) -> List[Tuple[str, str]]:\n",
    "    \"\"\"\n",
    "    将搜索结果的 JSON 字符串解析为标题-链接元组的列表。\n",
    "\n",
    "    参数：\n",
    "        results_string (str): 包含搜索结果的 JSON 格式字符串。\n",
    "\n",
    "    返回：\n",
    "        List[Tuple[str, str]]: 元组列表，每个元组包含搜索结果的标题和链接。\n",
    "                               如果解析失败，则返回空列表。\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 尝试解析 JSON 字符串\n",
    "        results = json.loads(results_string)\n",
    "        # 从每个结果中提取并返回标题和链接\n",
    "        return [(result.get('title', 'Untitled'), result.get('link', '')) for result in results]\n",
    "    except json.JSONDecodeError:\n",
    "        # 通过返回空列表处理 JSON 解码错误\n",
    "        print(\"Error parsing search results. Returning empty list.\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义 CRAG 流程的子函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_documents(query: str, faiss_index: FAISS, k: int = 3) -> List[str]:\n",
    "    \"\"\"\n",
    "    使用 FAISS 索引根据查询检索文档。\n",
    "\n",
    "    参数：\n",
    "        query (str): 要搜索的查询字符串。\n",
    "        faiss_index (FAISS): 用于相似性搜索的 FAISS 索引。\n",
    "        k (int): 要检索的顶部文档数量。默认为 3。\n",
    "\n",
    "    返回：\n",
    "        List[str]: 检索到的文档内容列表。\n",
    "    \"\"\"\n",
    "    docs = faiss_index.similarity_search(query, k=k)\n",
    "    return [doc.page_content for doc in docs]\n",
    "\n",
    "def evaluate_documents(query: str, documents: List[str]) -> List[float]:\n",
    "    \"\"\"\n",
    "    根据查询评估文档的相关性。\n",
    "\n",
    "    参数：\n",
    "        query (str): 查询字符串。\n",
    "        documents (List[str]): 要评估的文档内容列表。\n",
    "\n",
    "    返回：\n",
    "        List[float]: 每个文档的相关性得分列表。\n",
    "    \"\"\"\n",
    "    return [retrieval_evaluator(query, doc) for doc in documents]\n",
    "\n",
    "def perform_web_search(query: str) -> Tuple[List[str], List[Tuple[str, str]]]:\n",
    "    \"\"\"\n",
    "    根据查询执行网络搜索。\n",
    "\n",
    "    参数：\n",
    "        query (str): 要搜索的查询字符串。\n",
    "\n",
    "    返回：\n",
    "        Tuple[List[str], List[Tuple[str, str]]]: \n",
    "            - 从网络搜索获得的提炼知识列表。\n",
    "            - 包含来源标题和链接的元组列表。\n",
    "    \"\"\"\n",
    "    rewritten_query = rewrite_query(query)\n",
    "    web_results = search.run(rewritten_query)\n",
    "    web_knowledge = knowledge_refinement(web_results)\n",
    "    sources = parse_search_results(web_results)\n",
    "    return web_knowledge, sources\n",
    "\n",
    "def generate_response(query: str, knowledge: str, sources: List[Tuple[str, str]]) -> str:\n",
    "    \"\"\"\n",
    "    使用知识和来源生成对查询的响应。\n",
    "\n",
    "    参数：\n",
    "        query (str): 查询字符串。\n",
    "        knowledge (str): 用于响应的提炼知识。\n",
    "        sources (List[Tuple[str, str]]): 包含来源标题和链接的元组列表。\n",
    "\n",
    "    返回：\n",
    "        str: 生成的响应。\n",
    "    \"\"\"\n",
    "    response_prompt = PromptTemplate(\n",
    "        input_variables=[\"query\", \"knowledge\", \"sources\"],\n",
    "        template=\"Based on the following knowledge, answer the query. Include the sources with their links (if available) at the end of your answer:\\nQuery: {query}\\nKnowledge: {knowledge}\\nSources: {sources}\\nAnswer:\"\n",
    "    )\n",
    "    input_variables = {\n",
    "        \"query\": query,\n",
    "        \"knowledge\": knowledge,\n",
    "        \"sources\": \"\\n\".join([f\"{title}: {link}\" if link else title for title, link in sources])\n",
    "    }\n",
    "    response_chain = response_prompt | llm\n",
    "    return response_chain.invoke(input_variables).content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CRAG 流程\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crag_process(query: str, faiss_index: FAISS) -> str:\n",
    "    \"\"\"\n",
    "    通过检索、评估和使用文档或执行网络搜索来处理查询，以生成响应。\n",
    "\n",
    "    参数：\n",
    "        query (str): 要处理的查询字符串。\n",
    "        faiss_index (FAISS): 用于文档检索的 FAISS 索引。\n",
    "\n",
    "    返回：\n",
    "        str: 基于查询生成的响应。\n",
    "    \"\"\"\n",
    "    print(f\"\\nProcessing query: {query}\")\n",
    "\n",
    "    # 检索和评估文档\n",
    "    retrieved_docs = retrieve_documents(query, faiss_index)\n",
    "    eval_scores = evaluate_documents(query, retrieved_docs)\n",
    "    \n",
    "    print(f\"\\nRetrieved {len(retrieved_docs)} documents\")\n",
    "    print(f\"Evaluation scores: {eval_scores}\")\n",
    "\n",
    "    # 根据评估分数确定操作\n",
    "    max_score = max(eval_scores)\n",
    "    sources = []\n",
    "    \n",
    "    if max_score > 0.7:\n",
    "        print(\"\\nAction: Correct - Using retrieved document\")\n",
    "        best_doc = retrieved_docs[eval_scores.index(max_score)]\n",
    "        final_knowledge = best_doc\n",
    "        sources.append((\"Retrieved document\", \"\"))\n",
    "    elif max_score < 0.3:\n",
    "        print(\"\\nAction: Incorrect - Performing web search\")\n",
    "        final_knowledge, sources = perform_web_search(query)\n",
    "    else:\n",
    "        print(\"\\nAction: Ambiguous - Combining retrieved document and web search\")\n",
    "        best_doc = retrieved_docs[eval_scores.index(max_score)]\n",
    "        # 提炼检索到的知识\n",
    "        retrieved_knowledge = knowledge_refinement(best_doc)\n",
    "        web_knowledge, web_sources = perform_web_search(query)\n",
    "        final_knowledge = \"\\n\".join(retrieved_knowledge + web_knowledge)\n",
    "        sources = [(\"Retrieved document\", \"\")] + web_sources\n",
    "\n",
    "    print(\"\\nFinal knowledge:\")\n",
    "    print(final_knowledge)\n",
    "    \n",
    "    print(\"\\nSources:\")\n",
    "    for title, link in sources:\n",
    "        print(f\"{title}: {link}\" if link else title)\n",
    "\n",
    "    # 生成响应\n",
    "    print(\"\\nGenerating response...\")\n",
    "    response = generate_response(query, final_knowledge, sources)\n",
    "\n",
    "    print(\"\\nResponse generated\")\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 与文档高度相关的示例查询\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What are the main causes of climate change?\"\n",
    "result = crag_process(query, vectorstore)\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"Answer: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 与文档低相关的示例查询\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"how did harry beat quirrell?\"\n",
    "result = crag_process(query, vectorstore)\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"Answer: {result}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
