{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/explainable_retrieval.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 文档搜索中的可解释检索\n",
    "\n",
    "## 概述\n",
    "\n",
    "此代码实现了一个可解释的检索器，该系统不仅能根据查询检索相关文档，还能为每个检索到的文档提供相关性解释。它将基于向量的相似性搜索与自然语言解释相结合，增强了检索过程的透明度和可解释性。\n",
    "\n",
    "## 动机\n",
    "\n",
    "传统的文档检索系统通常像黑匣子一样工作，提供结果却不解释选择原因。在理解结果背后的推理至关重要的场景中，这种缺乏透明度可能会带来问题。可解释检索器通过提供对每个检索文档相关性的见解来解决此问题。\n",
    "\n",
    "## 关键组件\n",
    "\n",
    "1. 从输入文本创建向量存储\n",
    "2. 使用 FAISS 的基础检索器进行高效的相似性搜索\n",
    "3. 用于生成解释的语言模型 (LLM)\n",
    "4. 结合检索和解释生成的自定义 ExplainableRetriever 类\n",
    "\n",
    "## 方法详情\n",
    "\n",
    "### 文档预处理和向量存储创建\n",
    "\n",
    "1. 使用 OpenAI 的嵌入模型将输入文本转换为嵌入。\n",
    "2. 从这些嵌入创建一个 FAISS 向量存储，以进行高效的相似性搜索。\n",
    "\n",
    "### 检索器设置\n",
    "\n",
    "1. 从向量存储创建一个基础检索器，配置为返回前 5 个最相似的文档。\n",
    "\n",
    "### 解释生成\n",
    "\n",
    "1. 使用 LLM (GPT-4) 生成解释。\n",
    "2. 定义一个自定义提示模板，以指导 LLM 解释检索文档的相关性。\n",
    "\n",
    "### ExplainableRetriever 类\n",
    "\n",
    "1. 将基础检索器和解释生成结合到一个单一接口中。\n",
    "2. `retrieve_and_explain` 方法：\n",
    "   - 使用基础检索器检索相关文档。\n",
    "   - 为每个检索到的文档生成其与查询相关性的解释。\n",
    "   - 返回一个包含文档内容及其解释的字典列表。\n",
    "\n",
    "## 此方法的优点\n",
    "\n",
    "1. 透明度：用户可以理解为什么检索到特定的文档。\n",
    "2. 信任：解释能建立用户对系统结果的信心。\n",
    "3. 学习：用户可以深入了解查询和文档之间的关系。\n",
    "4. 调试：更容易识别和纠正检索过程中的问题。\n",
    "5. 定制化：可以为不同的用例或领域定制解释提示。\n",
    "\n",
    "## 结论\n",
    "\n",
    "可解释检索器是向更具可解释性和可信赖性的信息检索系统迈出的重要一步。通过在检索到的文档旁边提供自然语言解释，它弥合了强大的基于向量的搜索技术与人类理解之间的差距。这种方法在信息检索背后的推理与检索到的信息本身同等重要的各个领域具有潜在应用，例如法律研究、医疗信息系统和教育工具。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package Installation and Imports\n",
    "\n",
    "The cell below installs all necessary packages required to run this notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository to access helper functions and evaluation modules\n",
    "!git clone https://github.com/NirDiamant/RAG_TECHNIQUES.git\n",
    "import sys\n",
    "sys.path.append('RAG_TECHNIQUES')\n",
    "# If you need to run with the latest data\n",
    "# !cp -r RAG_TECHNIQUES/data ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "# Original path append replaced for Colab compatibility\n",
    "from helper_functions import *\n",
    "from evaluation.evalute_rag import *\n",
    "\n",
    "# Load environment variables from a .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Set the OpenAI API key environment variable\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the explainable retriever class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExplainableRetriever:\n",
    "    def __init__(self, texts):\n",
    "        self.embeddings = OpenAIEmbeddings()\n",
    "\n",
    "        self.vectorstore = FAISS.from_texts(texts, self.embeddings)\n",
    "        self.llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o-mini\", max_tokens=4000)\n",
    "\n",
    "        \n",
    "        # Create a base retriever\n",
    "        self.retriever = self.vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "        \n",
    "        # Create an explanation chain\n",
    "        explain_prompt = PromptTemplate(\n",
    "            input_variables=[\"query\", \"context\"],\n",
    "            template=\"\"\"\n",
    "            Analyze the relationship between the following query and the retrieved context.\n",
    "            Explain why this context is relevant to the query and how it might help answer the query.\n",
    "            \n",
    "            Query: {query}\n",
    "            \n",
    "            Context: {context}\n",
    "            \n",
    "            Explanation:\n",
    "            \"\"\"\n",
    "        )\n",
    "        self.explain_chain = explain_prompt | self.llm\n",
    "\n",
    "    def retrieve_and_explain(self, query):\n",
    "        # Retrieve relevant documents\n",
    "        docs = self.retriever.get_relevant_documents(query)\n",
    "        \n",
    "        explained_results = []\n",
    "        \n",
    "        for doc in docs:\n",
    "            # Generate explanation\n",
    "            input_data = {\"query\": query, \"context\": doc.page_content}\n",
    "            explanation = self.explain_chain.invoke(input_data).content\n",
    "            \n",
    "            explained_results.append({\n",
    "                \"content\": doc.page_content,\n",
    "                \"explanation\": explanation\n",
    "            })\n",
    "        \n",
    "        return explained_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a mock example and explainable retriever instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Usage\n",
    "texts = [\n",
    "    \"The sky is blue because of the way sunlight interacts with the atmosphere.\",\n",
    "    \"Photosynthesis is the process by which plants use sunlight to produce energy.\",\n",
    "    \"Global warming is caused by the increase of greenhouse gases in Earth's atmosphere.\"\n",
    "]\n",
    "\n",
    "explainable_retriever = ExplainableRetriever(texts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 展示结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Why is the sky blue?\"\n",
    "results = explainable_retriever.retrieve_and_explain(query)\n",
    "\n",
    "for i, result in enumerate(results, 1):\n",
    "    print(f\"Result {i}:\")\n",
    "    print(f\"Content: {result['content']}\")\n",
    "    print(f\"Explanation: {result['explanation']}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
