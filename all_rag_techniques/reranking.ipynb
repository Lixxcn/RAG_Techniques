{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/reranking.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG 系统中的重排方法\n",
    "\n",
    "## 概述\n",
    "重排是检索增强生成（RAG）系统中至关重要的一步，旨在提高检索文档的相关性和质量。它涉及重新评估和重新排序最初检索到的文档，以确保最相关的信息在后续处理或呈现中得到优先处理。\n",
    "\n",
    "## 动机\n",
    "在 RAG 系统中进行重排的主要动机是克服初始检索方法的局限性，这些方法通常依赖于更简单的相似性度量。重排允许进行更复杂的关联性评估，考虑到传统检索技术可能忽略的查询和文档之间的细微关系。此过程旨在通过确保在生成阶段使用最相关的信息来增强 RAG 系统的整体性能。\n",
    "\n",
    "## 关键组件\n",
    "重排系统通常包括以下组件：\n",
    "\n",
    "1. 初始检索器：通常是使用基于嵌入的相似性搜索的向量存储。\n",
    "2. 重排模型：可以是：\n",
    "   - 用于评分相关性的大型语言模型（LLM）\n",
    "   - 专门为相关性评估训练的交叉编码器模型\n",
    "3. 评分机制：一种为文档分配相关性分数的方法\n",
    "4. 排序和选择逻辑：根据新分数重新排序文档\n",
    "\n",
    "## 方法详情\n",
    "重排过程通常遵循以下步骤：\n",
    "\n",
    "1. 初始检索：获取一组潜在相关的文档。\n",
    "2. 配对创建：为每个检索到的文档创建查询-文档对。\n",
    "3. 评分：\n",
    "   - LLM 方法：使用提示要求 LLM 评估文档相关性。\n",
    "   - 交叉编码器方法：将查询-文档对直接输入模型。\n",
    "4. 分数解释：解析和规范化相关性分数。\n",
    "5. 重新排序：根据其新的相关性分数对文档进行排序。\n",
    "6. 选择：从重新排序的列表中选择前 K 个文档。\n",
    "\n",
    "## 此方法的优点\n",
    "重排具有以下几个优点：\n",
    "\n",
    "1. 提高相关性：通过使用更复杂的模型，重排可以捕捉到细微的相关性因素。\n",
    "2. 灵活性：可以根据具体需求和资源应用不同的重排方法。\n",
    "3. 增强上下文质量：向 RAG 系统提供更相关的文档可以提高生成响应的质量。\n",
    "4. 减少噪音：重排有助于过滤掉不太相关的信息，专注于最相关的内容。\n",
    "\n",
    "## 结论\n",
    "重排是 RAG 系统中一种强大的技术，可显著提高检索信息的质量。无论是使用基于 LLM 的评分还是专门的交叉编码器模型，重排都可以对文档相关性进行更细致、更准确的评估。这种提高的相关性直接转化为下游任务更好的性能，使重排成为高级 RAG 实现中必不可少的组件。\n",
    "\n",
    "在基于 LLM 和交叉编码器的重排方法之间进行选择，取决于所需准确性、可用计算资源和特定应用需求等因素。两种方法都比基本检索方法有实质性改进，并有助于 RAG 系统的整体有效性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "\n",
    "<img src=\"../images/reranking-visualization.svg\" alt=\"rerank llm\" style=\"width:100%; height:auto;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "\n",
    "<img src=\"../images/reranking_comparison.svg\" alt=\"rerank llm\" style=\"width:100%; height:auto;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 包安装和导入\n",
    "\n",
    "下面的单元格安装了运行此笔记本所需的所有必要软件包。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install langchain langchain-openai python-dotenv sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository to access helper functions and evaluation modules\n",
    "!git clone https://github.com/NirDiamant/RAG_TECHNIQUES.git\n",
    "import sys\n",
    "sys.path.append('RAG_TECHNIQUES')\n",
    "# If you need to run with the latest data\n",
    "# !cp -r RAG_TECHNIQUES/data ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "from langchain.docstore.document import Document\n",
    "from typing import List, Dict, Any, Tuple\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_core.retrievers import BaseRetriever\n",
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "\n",
    "# Original path append replaced for Colab compatibility\n",
    "from helper_functions import *\n",
    "from evaluation.evalute_rag import *\n",
    "\n",
    "# Load environment variables from a .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Set the OpenAI API key environment variable\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义文档路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download required data files\n",
    "import os\n",
    "os.makedirs('data', exist_ok=True)\n",
    "\n",
    "# Download the PDF document used in this notebook\n",
    "!wget -O data/Understanding_Climate_Change.pdf https://raw.githubusercontent.com/NirDiamant/RAG_TECHNIQUES/main/data/Understanding_Climate_Change.pdf\n",
    "!wget -O data/Understanding_Climate_Change.pdf https://raw.githubusercontent.com/NirDiamant/RAG_TECHNIQUES/main/data/Understanding_Climate_Change.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/Understanding_Climate_Change.pdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建向量存储"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = encode_pdf(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 方法1：基于 LLM 的函数对检索到的文档进行重排"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "\n",
    "<img src=\"../images/rerank_llm.svg\" alt=\"rerank llm\" style=\"width:40%; height:auto;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a custom reranking function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RatingScore(BaseModel):\n",
    "    relevance_score: float = Field(..., description=\"The relevance score of a document to a query.\")\n",
    "\n",
    "def rerank_documents(query: str, docs: List[Document], top_n: int = 3) -> List[Document]:\n",
    "    prompt_template = PromptTemplate(\n",
    "        input_variables=[\"query\", \"doc\"],\n",
    "        template=\"\"\"On a scale of 1-10, rate the relevance of the following document to the query. Consider the specific context and intent of the query, not just keyword matches.\n",
    "        Query: {query}\n",
    "        Document: {doc}\n",
    "        Relevance Score:\"\"\"\n",
    "    )\n",
    "    \n",
    "    llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\", max_tokens=4000)\n",
    "    llm_chain = prompt_template | llm.with_structured_output(RatingScore)\n",
    "    \n",
    "    scored_docs = []\n",
    "    for doc in docs:\n",
    "        input_data = {\"query\": query, \"doc\": doc.page_content}\n",
    "        score = llm_chain.invoke(input_data).relevance_score\n",
    "        try:\n",
    "            score = float(score)\n",
    "        except ValueError:\n",
    "            score = 0  # Default score if parsing fails\n",
    "        scored_docs.append((doc, score))\n",
    "    \n",
    "    reranked_docs = sorted(scored_docs, key=lambda x: x[1], reverse=True)\n",
    "    return [doc for doc, _ in reranked_docs[:top_n]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example usage of the reranking function with a sample query relevant to the document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What are the impacts of climate change on biodiversity?\"\n",
    "initial_docs = vectorstore.similarity_search(query, k=15)\n",
    "reranked_docs = rerank_documents(query, initial_docs)\n",
    "\n",
    "# print first 3 initial documents\n",
    "print(\"Top initial documents:\")\n",
    "for i, doc in enumerate(initial_docs[:3]):\n",
    "    print(f\"\\nDocument {i+1}:\")\n",
    "    print(doc.page_content[:200] + \"...\")  # Print first 200 characters of each document\n",
    "\n",
    "\n",
    "# Print results\n",
    "print(f\"Query: {query}\\n\")\n",
    "print(\"Top reranked documents:\")\n",
    "for i, doc in enumerate(reranked_docs):\n",
    "    print(f\"\\nDocument {i+1}:\")\n",
    "    print(doc.page_content[:200] + \"...\")  # Print first 200 characters of each document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a custom retriever based on our reranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom retriever class\n",
    "class CustomRetriever(BaseRetriever, BaseModel):\n",
    "    \n",
    "    vectorstore: Any = Field(description=\"Vector store for initial retrieval\")\n",
    "\n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "    def get_relevant_documents(self, query: str, num_docs=2) -> List[Document]:\n",
    "        initial_docs = self.vectorstore.similarity_search(query, k=30)\n",
    "        return rerank_documents(query, initial_docs, top_n=num_docs)\n",
    "\n",
    "\n",
    "# Create the custom retriever\n",
    "custom_retriever = CustomRetriever(vectorstore=vectorstore)\n",
    "\n",
    "# Create an LLM for answering questions\n",
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
    "\n",
    "# Create the RetrievalQA chain with the custom retriever\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=custom_retriever,\n",
    "    return_source_documents=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = qa_chain({\"query\": query})\n",
    "\n",
    "print(f\"\\nQuestion: {query}\")\n",
    "print(f\"Answer: {result['result']}\")\n",
    "print(\"\\nRelevant source documents:\")\n",
    "for i, doc in enumerate(result[\"source_documents\"]):\n",
    "    print(f\"\\nDocument {i+1}:\")\n",
    "    print(doc.page_content[:200] + \"...\")  # Print first 200 characters of each document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example that demonstrates why we should use reranking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison of Retrieval Techniques\n",
      "==================================\n",
      "Query: what is the capital of france?\n",
      "\n",
      "Baseline Retrieval Result:\n",
      "\n",
      "Document 1:\n",
      "The capital of France is great.\n",
      "\n",
      "Document 2:\n",
      "The capital of France is beautiful.\n",
      "\n",
      "Advanced Retrieval Result:\n",
      "\n",
      "Document 1:\n",
      "I really enjoyed my trip to Paris, France. The city is beautiful and the food is delicious. I would love to visit again. Such a great capital city.\n",
      "\n",
      "Document 2:\n",
      "Have you ever visited Paris? It is a beautiful city where you can eat delicious food and see the Eiffel Tower. \n",
      "    I really enjoyed all the cities in france, but its capital with the Eiffel Tower is my favorite city.\n"
     ]
    }
   ],
   "source": [
    "chunks = [\n",
    "    \"The capital of France is great.\",\n",
    "    \"The capital of France is huge.\",\n",
    "    \"The capital of France is beautiful.\",\n",
    "    \"\"\"Have you ever visited Paris? It is a beautiful city where you can eat delicious food and see the Eiffel Tower. \n",
    "    I really enjoyed all the cities in france, but its capital with the Eiffel Tower is my favorite city.\"\"\", \n",
    "    \"I really enjoyed my trip to Paris, France. The city is beautiful and the food is delicious. I would love to visit again. Such a great capital city.\"\n",
    "]\n",
    "docs = [Document(page_content=sentence) for sentence in chunks]\n",
    "\n",
    "\n",
    "def compare_rag_techniques(query: str, docs: List[Document] = docs) -> None:\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    vectorstore = FAISS.from_documents(docs, embeddings)\n",
    "\n",
    "    print(\"Comparison of Retrieval Techniques\")\n",
    "    print(\"==================================\")\n",
    "    print(f\"Query: {query}\\n\")\n",
    "    \n",
    "    print(\"Baseline Retrieval Result:\")\n",
    "    baseline_docs = vectorstore.similarity_search(query, k=2)\n",
    "    for i, doc in enumerate(baseline_docs):\n",
    "        print(f\"\\nDocument {i+1}:\")\n",
    "        print(doc.page_content)\n",
    "\n",
    "    print(\"\\nAdvanced Retrieval Result:\")\n",
    "    custom_retriever = CustomRetriever(vectorstore=vectorstore)\n",
    "    advanced_docs = custom_retriever.get_relevant_documents(query)\n",
    "    for i, doc in enumerate(advanced_docs):\n",
    "        print(f\"\\nDocument {i+1}:\")\n",
    "        print(doc.page_content)\n",
    "\n",
    "\n",
    "query = \"what is the capital of france?\"\n",
    "compare_rag_techniques(query, docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2: Cross Encoder models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "\n",
    "<img src=\"../images/rerank_cross_encoder.svg\" alt=\"rerank cross encoder\" style=\"width:40%; height:auto;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the cross encoder class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
    "\n",
    "class CrossEncoderRetriever(BaseRetriever, BaseModel):\n",
    "    vectorstore: Any = Field(description=\"Vector store for initial retrieval\")\n",
    "    cross_encoder: Any = Field(description=\"Cross-encoder model for reranking\")\n",
    "    k: int = Field(default=5, description=\"Number of documents to retrieve initially\")\n",
    "    rerank_top_k: int = Field(default=3, description=\"Number of documents to return after reranking\")\n",
    "\n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "    def get_relevant_documents(self, query: str) -> List[Document]:\n",
    "        # Initial retrieval\n",
    "        initial_docs = self.vectorstore.similarity_search(query, k=self.k)\n",
    "        \n",
    "        # Prepare pairs for cross-encoder\n",
    "        pairs = [[query, doc.page_content] for doc in initial_docs]\n",
    "        \n",
    "        # Get cross-encoder scores\n",
    "        scores = self.cross_encoder.predict(pairs)\n",
    "        \n",
    "        # Sort documents by score\n",
    "        scored_docs = sorted(zip(initial_docs, scores), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # Return top reranked documents\n",
    "        return [doc for doc, _ in scored_docs[:self.rerank_top_k]]\n",
    "\n",
    "    async def aget_relevant_documents(self, query: str) -> List[Document]:\n",
    "        raise NotImplementedError(\"Async retrieval not implemented\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an instance and showcase over an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the cross-encoder retriever\n",
    "cross_encoder_retriever = CrossEncoderRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    cross_encoder=cross_encoder,\n",
    "    k=10,  # Retrieve 10 documents initially\n",
    "    rerank_top_k=5  # Return top 5 after reranking\n",
    ")\n",
    "\n",
    "# Set up the LLM\n",
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
    "\n",
    "# Create the RetrievalQA chain with the cross-encoder retriever\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=cross_encoder_retriever,\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "# Example query\n",
    "query = \"What are the impacts of climate change on biodiversity?\"\n",
    "result = qa_chain({\"query\": query})\n",
    "\n",
    "print(f\"\\nQuestion: {query}\")\n",
    "print(f\"Answer: {result['result']}\")\n",
    "print(\"\\nRelevant source documents:\")\n",
    "for i, doc in enumerate(result[\"source_documents\"]):\n",
    "    print(f\"\\nDocument {i+1}:\")\n",
    "    print(doc.page_content[:200] + \"...\")  # Print first 200 characters of each document"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
