{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/HyDe_Hypothetical_Document_Embedding.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 文档检索中的假设性文档嵌入 (HyDE)\n",
    "\n",
    "## 概述\n",
    "\n",
    "此代码实现了一个用于文档检索的假设性文档嵌入 (HyDE) 系统。HyDE 是一种创新方法，它将查询问题转换为包含答案的假设性文档，旨在弥合向量空间中查询和文档分布之间的差距。\n",
    "\n",
    "## 动机\n",
    "\n",
    "传统的检索方法通常难以解决短查询与更长、更详细的文档之间的语义差距。HyDE 通过将查询扩展为一个完整的假设性文档来解决这个问题，通过使查询表示在向量空间中与文档表示更相似，从而可能提高检索相关性。\n",
    "\n",
    "## 关键组件\n",
    "\n",
    "1. PDF 处理和文本分块\n",
    "2. 使用 FAISS 和 OpenAI 嵌入创建向量存储\n",
    "3. 用于生成假设性文档的语言模型\n",
    "4. 实现 HyDE 技术的自定义 HyDERetriever 类\n",
    "\n",
    "## 方法详情\n",
    "\n",
    "### 文档预处理和向量存储创建\n",
    "\n",
    "1. 处理 PDF 并将其拆分为块。\n",
    "2. 使用 OpenAI 嵌入创建 FAISS 向量存储，以实现高效的相似性搜索。\n",
    "\n",
    "### 假设性文档生成\n",
    "\n",
    "1. 使用语言模型 (GPT-4) 生成一个回答给定查询的假设性文档。\n",
    "2. 生成过程由一个提示模板引导，该模板确保假设性文档详细并与向量存储中使用的块大小相匹配。\n",
    "\n",
    "### 检索过程\n",
    "\n",
    "`HyDERetriever` 类实现以下步骤：\n",
    "\n",
    "1. 使用语言模型从查询中生成一个假设性文档。\n",
    "2. 将假设性文档用作向量存储中的搜索查询。\n",
    "3. 检索与此假设性文档最相似的文档。\n",
    "\n",
    "## 主要特点\n",
    "\n",
    "1. 查询扩展：将短查询转换为详细的假设性文档。\n",
    "2. 灵活配置：允许调整块大小、重叠和检索到的文档数量。\n",
    "3. 与 OpenAI 模型集成：使用 GPT-4 进行假设性文档生成，并使用 OpenAI 嵌入进行向量表示。\n",
    "\n",
    "## 这种方法的好处\n",
    "\n",
    "1. 提高相关性：通过将查询扩展为完整文档，HyDE 可以潜在地捕获更细致和相关的匹配。\n",
    "2. 处理复杂查询：对于可能难以直接匹配的复杂或多方面查询特别有用。\n",
    "3. 适应性：假设性文档生成可以适应不同类型的查询和文档领域。\n",
    "4. 更好地理解上下文的潜力：扩展后的查询可能更好地捕捉原始问题背后的上下文和意图。\n",
    "\n",
    "## 实现细节\n",
    "\n",
    "1. 使用 OpenAI 的 ChatGPT 模型进行假设性文档生成。\n",
    "2. 使用 FAISS 在向量空间中进行高效的相似性搜索。\n",
    "3. 允许轻松可视化假设性文档和检索到的结果。\n",
    "\n",
    "## 结论\n",
    "\n",
    "假设性文档嵌入 (HyDE) 代表了一种创新的文档检索方法，解决了查询和文档之间的语义差距。通过利用先进的语言模型将查询扩展为假设性文档，HyDE 有可能显著提高检索相关性，特别是对于复杂或细致的查询。这种技术在理解查询意图和上下文至关重要的领域可能特别有价值，例如法律研究、学术文献综述或高级信息检索系统。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "\n",
    "<img src=\"../images/HyDe.svg\" alt=\"HyDe\" style=\"width:40%; height:auto;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "\n",
    "<img src=\"../images/hyde-advantages.svg\" alt=\"HyDe\" style=\"width:100%; height:auto;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 包安装和导入\n",
    "\n",
    "下面的单元格安装了运行此笔记本所需的所有必要软件包。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository to access helper functions and evaluation modules\n",
    "!git clone https://github.com/NirDiamant/RAG_TECHNIQUES.git\n",
    "import sys\n",
    "sys.path.append('RAG_TECHNIQUES')\n",
    "# If you need to run with the latest data\n",
    "# !cp -r RAG_TECHNIQUES/data ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "# Original path append replaced for Colab compatibility\n",
    "from helper_functions import *\n",
    "from evaluation.evalute_rag import *\n",
    "\n",
    "# Load environment variables from a .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Set the OpenAI API key environment variable\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义文档路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download required data files\n",
    "import os\n",
    "os.makedirs('data', exist_ok=True)\n",
    "\n",
    "# Download the PDF document used in this notebook\n",
    "!wget -O data/Understanding_Climate_Change.pdf https://raw.githubusercontent.com/NirDiamant/RAG_TECHNIQUES/main/data/Understanding_Climate_Change.pdf\n",
    "!wget -O data/Understanding_Climate_Change.pdf https://raw.githubusercontent.com/NirDiamant/RAG_TECHNIQUES/main/data/Understanding_Climate_Change.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/Understanding_Climate_Change.pdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义 HyDe 检索器类 - 创建向量存储、生成假设文档和检索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyDERetriever:\n",
    "    def __init__(self, files_path, chunk_size=500, chunk_overlap=100):\n",
    "        self.llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o-mini\", max_tokens=4000)\n",
    "\n",
    "        self.embeddings = OpenAIEmbeddings()\n",
    "        self.chunk_size = chunk_size\n",
    "        self.chunk_overlap = chunk_overlap\n",
    "        self.vectorstore = encode_pdf(files_path, chunk_size=self.chunk_size, chunk_overlap=self.chunk_overlap)\n",
    "    \n",
    "        \n",
    "        self.hyde_prompt = PromptTemplate(\n",
    "            input_variables=[\"query\", \"chunk_size\"],\n",
    "            template=\"\"\"Given the question '{query}', generate a hypothetical document that directly answers this question. The document should be detailed and in-depth.\n",
    "            the document size has be exactly {chunk_size} characters.\"\"\",\n",
    "        )\n",
    "        self.hyde_chain = self.hyde_prompt | self.llm\n",
    "\n",
    "    def generate_hypothetical_document(self, query):\n",
    "        input_variables = {\"query\": query, \"chunk_size\": self.chunk_size}\n",
    "        return self.hyde_chain.invoke(input_variables).content\n",
    "\n",
    "    def retrieve(self, query, k=3):\n",
    "        hypothetical_doc = self.generate_hypothetical_document(query)\n",
    "        similar_docs = self.vectorstore.similarity_search(hypothetical_doc, k=k)\n",
    "        return similar_docs, hypothetical_doc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a HyDe retriever instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = HyDERetriever(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstrate on a use case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_query = \"What is the main cause of climate change?\"\n",
    "results, hypothetical_doc = retriever.retrieve(test_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the hypothetical document and the retrieved documnets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_content = [doc.page_content for doc in results]\n",
    "\n",
    "print(\"hypothetical_doc:\\n\")\n",
    "print(text_wrap(hypothetical_doc)+\"\\n\")\n",
    "show_context(docs_content)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
